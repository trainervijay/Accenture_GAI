{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKJOkJ8ymIu"
      },
      "source": [
        "# **Schema**\n",
        "- Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "**Problem Statement**\n",
        "- Design and implement a schema for interacting with Large Language Models (LLMs) that ensures consistent, structured, and efficient communication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUU7dHAy40b"
      },
      "source": [
        "## **Text**\n",
        "- The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFFpbfTezUXu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN-Tn7S-zRtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import IPython\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-12-01-preview\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://azure-foundryai.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"8XKOy3RpaT5ptQrinrgJ0YdybpUeT0p1IeajFDU4mzDFxzjdQlu4JQQJ99BFACYeBjFXJ3w3AAAAACOGZxka\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtXSeHiyysP"
      },
      "source": [
        "## **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQMBQ1eOy1DR"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = AzureChatOpenAI(deployment_name=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZMOJ-3U0y-Y"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SCNi-wrj0hsF",
        "outputId": "79779aad-1ffc-4528-cd32-975bc99d2160"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How about a fresh Caprese salad with tomatoes, mozzarella, basil, and a drizzle of olive oil?'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGkM6TjsGRNz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZ6pJr51JVS"
      },
      "source": [
        "\n",
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG_MQHiz02Gf",
        "outputId": "23977a34-c3e2-4dbe-c916-18b126aef374"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Explore the Promenade des Anglais, enjoy fresh seafood at local restaurants, visit the colorful Old Town (Vieux Nice), and take in stunning views from Castle Hill.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkytXMI1M4A"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xNJqFOUo1LbX",
        "outputId": "2f26ab21-2b5a-4ca2-847d-08742e9615ce"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The day that comes after Thursday is **Friday**.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
